---
title: "Model code walkthrough"
authors:
  - name: Amy Heather
    url: https://github.com/amyheather
    orcid: 0000-0002-6596-3479
    affiliation: University of Exeter
format:
  html:
    toc: true
bibliography: ../docs/references.bib
csl: ../docs/elsvan.csl
---

## Purpose of this notebook

This is a (potentially temporary) notebook that I am keeping as I work through the model (copied from `Model_Structure.R`), writing down notes to explain each part to myself, to ensure I understand it.

To simplify this, I have removed the original comments, and so this just includes my comments that I needed to understand it. The benefit of this is that, once I have understood how it all works, I can use my comments below to inform any changes to the comments in `Model_Structure.R`, the function docstrings, or elsewhere. Once I have completed this notebook, I can also create the model overview pages.

::: {.callout-warning}

Whenever I have made changes to the code in `Model_Structure.R`, these are indicated with these boxes. This is excluding the removal of comments, which has been done throughout.

:::

::: {.callout-note collapse="false"}

Whenever I have add code or detailed explanation, to help explain and demonstrate what the model is doing, these are contained within these boxes.

:::

## Set up

### Import libraries

```{r}
#| output: false

library(shiny, quiet = TRUE)   
library(gtools, quiet = TRUE)
library(openxlsx, quiet = TRUE)
library(flexsurv, quiet = TRUE)
library(tidyverse, quiet = TRUE)
library(data.table, quiet = TRUE)
library(heemod, quiet = TRUE)
library(logOfGamma, quiet = TRUE)
library(ggplot2, quiet = TRUE)
library(survminer, quiet = TRUE)
library(officer, quiet = TRUE)
library(officedown, quiet = TRUE)
library(magrittr, quiet = TRUE)
library(Hmisc, quiet = TRUE)
library(future.apply, quiet = TRUE)
library(crosstable, quiet = TRUE)
library(flextable, quiet = TRUE)
library(stringr, quiet = TRUE)
library(BCEA, quiet = TRUE)
library(collapse, quiet = TRUE)
library(scales, quiet = TRUE)
library(Matrix, quiet = TRUE)
library(dplyr, quiet = TRUE)
library(progressr, quiet = TRUE)
library(microbenchmark, quiet = TRUE)
```

### Define some project settings

```{r}
keep_free_cores <- NA
if (any(is.na(keep_free_cores), keep_free_cores<0)) {
  plan(sequential)
} else {
  plan(multisession(workers = max(availableCores()-keep_free_cores,1)))
}
```

::: {.callout-note collapse="true"}

Recorded time to get to **complete 3 active treatment lines for population 1**, then repeated with other cores, to understand what is faster / slower:

* 28 cores: > 53m (still on 3)
* 12 cores: 35m
* 8 cores: < 19m
* 4 cores: 7m
* Sequential (i.e. `NA`): 3m

To run full script **sequentially** on that **remote machine**, it took **19 minutes**.

:::

```{r}
# Other generic settings for the progress bar and units for table widths
handlers("progress")
options(crosstable_units="cm")
```

::: {.callout-note collapse="true"}

`handlers("progress")`: `progressr` function, settings for how progress is reported

`options(crosstable_units="cm")`: `crosstable` package generates descriptive statistics with function `crosstable()`, and this is the settings for it (although can't spot us of `crosstable()` anywhere)

:::

```{r}
qc_mode <- FALSE
```

::: {.callout-note collapse="true"}

`qc_mode` is just used in `survival_functions.R` and by `f_NMA_AddAssumptionsToNetwork()` (and perhaps others if it calls them) and it is the input for `verbose` (i.e. if true, there will be extra outputs to console)

:::

### Get functions

::: {.callout-warning collapse="true"}

I've modified this to make path defined once, as needed to change it, and to define paths that occur later on in the script. Hence, you'll spot the changes later in the code also for `excel_path` and `empty_results_path`.

:::

```{r}
# Set path to folders
path_data = "../1_Data"
path_functions = "../3_Functions"
path_output = "../4_Output"

# Set paths to files loaded in this script
excel_path <- file.path(path_data, "ID6184_RCC_model inputs FAD version [UK RWE unredacted, ACIC redacted, cPAS redacted].xlsm")
excel_path2 <- file.path(path_data, "IPD_R_input_noACIC.xlsx")
empty_results_path = file.path(path_functions, "reporting/empty results doc.docx")
RDS_path <- file.path(path_data, "survival_analysis_no_ipd_CompanyTTDTTPPPS_redacted.rds")
RDS_path2 <- file.path(path_data, "PH_NMA_CODA.rds")
RDS_path3 <- file.path(path_data, "FPNMA_means.rds")

# Source functions
source(file.path(path_functions, "excel/extract.R"))
source(file.path(path_functions, "sequencing/sequences.R"))
source(file.path(path_functions, "survival/Survival_functions.R"))
source(file.path(path_functions, "survival/other_cause_mortality.R"))
source(file.path(path_functions, "survival/treatment_effect_waning.R"))
source(file.path(path_functions, "misc/other.R"))
source(file.path(path_functions, "misc/shift_and_pad.R"))
source(file.path(path_functions, "misc/cleaning.R"))
source(file.path(path_functions, "misc/nesting.R"))
source(file.path(path_functions, "misc/discounting.R"))
source(file.path(path_functions, "misc/qdirichlet.R"))
source(file.path(path_functions, "misc/plotting.R"))
source(file.path(path_functions, "misc/structure.R"))
source(file.path(path_functions, "misc/fpnma_fns.R"))
source(file.path(path_functions, "utility/age_related.R"))
source(file.path(path_functions, "costs_and_QALYs/utility_processing.R"))
source(file.path(path_functions, "adverse_events/AE_steps.R"))
source(file.path(path_functions, "costs_and_QALYs/cost_processing.R"))
source(file.path(path_functions, "markov/markov.R"))
source(file.path(path_functions, "patient_flow/overarching.R"))
source(file.path(path_functions, "patient_flow/partitioned_survival.R"))
source(file.path(path_functions, "patient_flow/markov.R"))
source(file.path(path_functions, "patient_flow/drug_costs.R"))
source(file.path(path_functions, "patient_flow/hcru_costs.R"))
source(file.path(path_functions, "patient_flow/qalys.R"))
source(file.path(path_functions, "patient_flow/ae.R"))
source(file.path(path_functions, "results/incremental_analysis.R"))
source(file.path(path_functions, "results/model_averaging.R"))
source(file.path(path_functions, "results/partitioned_survival.R"))
source(file.path(path_functions, "misc/severity_modifier.R"))
source(file.path(path_functions, "results/results_tables.R"))
source(file.path(path_functions, "psa/psa functions.R"))
source(file.path(path_functions, "reporting/word_document_output.R"))
```

::: {.callout-note collapse="true"}

Not sure of purpose as doesn't appear to be used anywhere - might be legacy code.

:::

```{r}
User_types <- c("Submitting company", "NICE", "EAG", "Committee", "NHSE", "Clinical expert", "Patient expert", "Non-intervention stakeholder", "Public")
```

## Define model parameters

### Get inputs from excel workbook and save as list `i`

::: {.callout-warning collapse="true"}

Hidden output as it is quite verbose.

:::

```{r}
if (file.exists(excel_path)) {
  i <- f_excel_extract(excel_path, verbose = FALSE)
} else {
  i <- f_excel_extract(rstudioapi::selectFile(
    caption = "Select the Excel inputs file (ID6184_RCC_model inputs....xlsm)",
    label = "ID6184_RCC_model inputs....xlsm",
    path = "../1_Data/",
    filter = "Excel Files (*.xlsm)",
    existing = TRUE
  ), verbose = FALSE)
}
```

::: {.callout-note collapse="true"}

Import the file at `excel_path` using `f_excel_extract()`. If the file doesn't exist, assuming the user is in RStudio, a dialog box will appear with the system files, and the user should then select a file from their directory. The dialog will open in `1_Data/`, show only `.xlsm` files, and the accept/ok button has the text `ID6184_RCC_model inputs....xlsm`.

The function `f_excel_extract` is below (note: `sheets` not used).

```{r}
f_excel_extract <- function(path_to_excel_file, verbose = FALSE) {
  
  wb          <- loadWorkbook(path_to_excel_file)
  sheets      <- wb$sheet_names
  named       <- getNamedRegions(wb)
  nams        <- unlist(as.list(named))
  names(nams) <- nams
  
  # Cycle through all the named ranges, making a decision on cleaning as we go
  output <- lapply(nams, function(named_range) {
    
    if (verbose) cat(paste0("Extracting named range ", named_range, " from ", path_to_excel_file, "\n"))
    dat <- read.xlsx(wb,namedRegion = named_range, check.names = TRUE,colNames = TRUE)
    
    if (nrow(dat) == 0) {
      # if it has 0 rows, then the input must be a 1 cell one, so we can safely assume
      # no row names
      dat <- read.xlsx(wb,namedRegion = named_range,colNames = FALSE,rowNames = FALSE)
      
      if (all(length(dat) == 1, names(dat)[1] == "X1")) {
        dat <- unlist(dat, use.names = FALSE)
      } else if(nrow(dat) == 1) {
        dat <- unlist(read.xlsx(wb,namedRegion = named_range,colNames = FALSE,rowNames = FALSE), use.names = F)
      } 
      
      return(dat)
    } else if(ncol(dat) == 1) {
      # if there's 1 column, then it's actually just a vector:
      dat <- unlist(read.xlsx(wb,namedRegion = named_range,colNames = FALSE,rowNames = FALSE), use.names = F)
    } else {
      # logically we can't identify whether a table has appropriate names or not
      # at this point. this will have to be left to the cleaning functions.
      return(dat)
    }
  })
  
  # Drop the workbook at the end (I think in {} this would happen anyway, but want to ensure!)
  rm(wb)
  return(output)
}
```

It loops through `named_range`, which is returned by `openxlsx::getNamedRegions()`. This is a function that finds all the named regions in an excel file.

Named regions consist of:

* A name for the region (e.g. `apply_waning_to`)
* The region, which consists of the sheet, column/s and row/s (e.g. `=Lists!$Y$10:$Y$11`)

In this workbook, the named regions are all stored in a sheet called `named ranges`.

When this function runs, it creates a list called `i` and each element of that list reflects a row from the `named ranges sheet`, except the first element, which is each of the named ranges.

Named ranges:

```{r}
head(i[[1]])
head(i$`_xlnm._FilterDatabase`)
```

**Example** `apply_waning_to` was from `=Lists!$Y$10:$Y$11`. Looking in the `Lists` sheet, we can see that Y10 was `ref trt hazard` and Y11 was `ref trt abs surv`. This matches up with the returned object:

```{r}
i[[2]]
i$apply_waning_to
```

**Example 2:** `dd_age_sex_source` is from `='Model settings'!$G$63`. Looking in the `Model settings` sheet, we can see that G63 is the answer to "Age/sex based on mean or PLD?", with base case/default being `PLD`. We can likewise see this from its value in the list:

```{r}
i[[11]]
i$dd_age_sex_source
```

:::

```{r}
i <- c(i,f_excel_cleanParams(i$R_table_param))
```

::: {.callout-note collapse="true"}

One of the items in the list `i` is `R_table_param`. The source of this in the excel workbook was `='All parameters'!$C$5:$Q$2912` - so basically, it's just taking the full table from the sheet `All parameters`.

```{r}
head(i$R_table_param)
```

The function `f_excel_cleanParams()` takes this table and turns each row into a list, which you can access using `Parameter.name`. It adds an extra element `Mean`, which is just the value from `Mean.current.value` converted to numeric.

```{r}
show_list <- f_excel_cleanParams(i$R_table_param)
show_list$cabo_nivo_include
```

When it did this, it then concatenated that list with the list `i`, meaning that each of those elements can now be accessed in the same way from `i`.

```{r}
i$cabo_nivo_include
```

:::

### Add some extra inputs to the list `i`

```{r}
i$decision_problem <- "cabo+nivo"

i$id     <- list(ipd = list())
i$lookup <- list(ipd = list())

i$distnames <- 
  c(
    gengamma      = "gengamma",
    exp           = "exp",
    weibull       = "weibull",
    lnorm         = "lnorm",
    gamma         = "gamma",
    gompertz      = "gompertz",
    llogis        = "llogis"
  )
```

### Use `i` to make new list `p` (some elements same, some used in calculations to make new elements)

```{r}
p <- f_misc_param_generate_p(i)
```

::: {.callout-note collapse="true"}

The function `structure::f_misc_param_generate_p()` simply takes some of the elements from `i` and creates a new list `p`.

For example, these are both the same:

```{r}
p$basic$th_y
i$ui_time_horizon
```

See the full outline of what elements it takes by looking at the function:

```{r}
#' Function which creates an empty version of the parameters list p and populates
#' it using the inputs from i
#' 
#' @param i raw extracted inputs from Excel
#' 
f_misc_param_generate_p <- function(i) {
  
  p <- list(
    basic = list(
      th   = ceiling(i$ui_time_horizon * 365.25 / 7), 
      th_y = i$ui_time_horizon, 
      cl_d = i$i_cycle_length_weeks*7, 
      cl_w = i$i_cycle_length_weeks, 
      cl_y = i$i_cycle_length_weeks*7/365.25, 
      discQ = i$ui_disc_qaly,
      discC = i$ui_disc_cost,
      structure = str_trim(i$dd_model_struct)
    ),
    demo = list(
      table = data.table(i$R_table_ptchar)
    ), # patient demographic data
    seq   = list(), # treatment sequences. same for both model structures.
    surv  = list(), # Survival extrapolations (if needed for iteration, i.e. in part surv model). same for both model structures
    releff = list(), # Relative efficacy network, for use populating the disease model. same for both model structures
    costs  = list(
      mk = list(),
      ps = list(),
      settings = list(
        subsTx = data.table(i$R_table_sub_txts_prop_n_costs)
      )
    ), # All drug inputs after they've been processed and tidied up
    util  = list(
      mk = list(),
      ps = list()
    ), # All inputs to apply to the disease model
    ae    = list(
      mk = list(),
      ps = list()
    ), # Inputs to generate AE matrices AC and AQ
    misc  = list(
      mk = list(),
      ps = list(),
      plot = list(
        xlim_survplots_yr = 20
      )
    )
  )
  
  p$basic$n_cyc <- ceiling(p$basic$th) # rounding up to a whole number
  p$basic$t_cyc <- rep(0:p$basic$n_cyc)
  p$basic$t_yr  <- p$basic$t_cyc*7/365.25
  
  # discount factors - base-case edition. These will get replaced for scenarios affecting
  # discount rates or the time horizon
  p$basic$discFacQ <- f_discFac(p$basic$discQ,p$basic$t_yr)
  p$basic$discFacC <- f_discFac(p$basic$discC,p$basic$t_yr)
  
  return(p)
  
}
```

:::

### Add some more inputs to `p`

```{r}
p$basic$R_maxlines <- 4

p$basic$decision_problem <- i$decision_problem
```

::: {.callout-note collapse="true"}

I'm pretty sure that max lines is referring to the maximum number of treatment lines. The most it can be is 4. But I don't know if perhaps you can change this to 2 to reduce the number in model? Or if this is a standard unchanging parameter as the model is only designed to go up to 4?

:::

## Sequences

### Find all the possible combinations and orders of treatment and add to `i`

```{r}
i$sequences <- f_generate_sequences(
  comparators = i$List_comparators, 
  maxlines    = p$basic$R_maxlines
)
```

::: {.callout-note collapse="true"}

This adds a new element to `i` called `sequences`.

```{r}
head(i$sequences)
```

It's created using `sequences::f_generate_sequences()`. The inputs to this were:

```{r}
i$List_comparators
p$basic$R_maxlines
```

The output of the function is a table where each column is the line of therapy. The final column is always best supportive care (BSC). The first four columns reflect every possible order and combination of treatments (e.g. ABCD, ABCE, ABCF... and so on). The total possiblities are:

```{r}
dim(i$sequences)
```

:::

### Filter to valid combinations/sequences

```{r}
i$sequences <- as.data.frame(i$sequences)

populations <- i$i_nr_populations

seqs <- NULL
for (population in 1:populations) {
  cat("Applying sequence restrictions to population", population,"\n")
  
  s <- f_path_tx_restrict(
    sequences                = i$sequences,
    allowed                  = f_get_allowed_lists(i, population), #overall list of allowed drugs in this popn
    L1                       = f_get_L1_lists(i, population), # 1L drugs allowed in this popn
    L2                       = f_get_L2_lists(i, population), # 2L drugs allowed in this popn
    L3                       = f_get_L3_lists(i, population), # 3L drugs allowed in this popn
    L4                       = f_get_L4_lists(i, population), # 4L drugs allowed in this popn
    only_after               = f_get_only_after_lists(i, population), #list of restrictions where tx can be only after the listed txs
    not_immediate_after      = f_get_not_immediate_after_lists(i, population), #list of restrictions where tx can be only immediately before the listed txs
    one_in_list              = f_get_one_in_list_lists(i, population), #list of restrictions where only one of the tx in each list is allowed 
    only_after_one           = f_get_only_after_one_lists(i, population), #list of restrictions where only one of the listed treatments is allowed prior to current therapy 
    L2_only_after            = f_get_2L_only_after_lists(i, population), #list of 2L+ restrictions: if drug is used 2L, 3L or 4L, can only be after drug x
    L2_only_immediate_after  = f_get_2L_only_immediate_after_lists(i, population), #list of 2L+ restrictions: if drug is used 2L, 3L or 4L, can only be immediately after drug x
    L2_only_one              = f_get_2L_only_one_lists(i, population) #list of 2L+ drugs where only one of them allowed in a given sequence
  )
  s <- cbind(rep(paste0("pop", population),nrow(s)), s)
  colnames(s) <- paste0('V', seq_len(ncol(s))) # rbind no longer likes un-named columns so added this
  seqs <- rbind(seqs, s)
}
rownames(seqs) <- NULL
```

::: {.callout-note collapse="true"}

## Introduction to `f_path_tx_restrict`

`f_path_tx_restrict` is defined in two .R files: `rccFunctions.R` and `sequences.R`. In this script, we did not use `rccFunctions.R`, and just sourced `sequences.R`.

This has substantially reduced the number of rows with possible sequence combinations in `i$sequences`:

```{r}
dim(i$sequences)
```

It utilises several other functions from `sequences.R`, each taking the input of `i` and `population`, where population is an element from:

```{r}
i$i_nr_populations
```

We can see from the excel spreadsheet that this is the value for total populations from `Lists`, and that above it it mentions the popoulations:

* pop1	>12m since IO, favourable risk
* pop2	>12m since IO, intermed/poor risk
* pop3	<12m since IO, favourable risk
* pop4	<12m since IO, intermed/poor risk

IO refers to immuno-ocology. also known as immunotherapy.

The risks are as defined in the International Metastatic Renal Cell Carcinoma Database Consortium (IMDC) criteria. RCC can be defined as either:

* **Favourable-risk** disease/cancer/RCC
* **Intermediate- and poor-risk** disease/cancer/RCC

This then guides treatment decisions:

* Treatments for all risk groups (i.e. favourable, intermediate or poor) include "sunitinib, pazopanib, tivozanib or avelumab plus axitinib"
* Additional treatments for intermediate- or poor-risk cancer are "nivolumab plus ipilimumab, lenvatinib plus pembrolizumab, or cabozantinib" @national_institute_for_health_and_care_excellence_nice_cabozantinib_2024

:::

::: {.callout-note collapse="true"}

## Explanation of `f_get_allowed_lists()`

The first function used within `f_path_tx_restrict()` is `f_get_allowed_lists()` to get the value for `allowed`.

```{r}
f_get_allowed_lists <- function(i, population) {
  output <- i[grep("allowed", names(i))]
  output <- output[grep(paste0("pop", population), names(output))]
  output <- output[!(grepl("only_one_allowed", names(output)))]
  names(output) <- sub(paste0("List_","pop",population,"_"), "", names(output))
  f_check_drugnames(i, output)
  return(output)
}
```

The first thing this function does is find all the "allowed" lists from `i`. As you can see, there are several lists defined for each population.

```{r}
output <- i[grep("allowed", names(i))]
names(output)
```

It then filters to one of the populations (`pop1`, `pop2`, `pop3` or `pop4`). For example, for `pop1`...

```{r}
population <- 1

output <- output[grep(paste0("pop", population), names(output))]
output
```

It removes the lists that said `only_one_allowed`.

```{r}
output <- output[!(grepl("only_one_allowed", names(output)))]
output
```

Finally, it renames the lists to remove the words `List` and `pop1`(2/3/4).

```{r}
names(output) <- sub(paste0("List_","pop",population,"_"), "", names(output))
output
```

This checks that each of the names in the list match the names in `i$List_comparators`, and will stop the code and return an error message if any do not.

```{r}
i$List_comparators
```

```{r}
f_check_drugnames(i, output)
```

:::

::: {.callout-note collapse="true"}

## Returning to `f_path_tx_restrict`

The result from the function above is input into `f_path_tx_restrict` as `allowed`, and used in a single line, to remove drugs not allowed for that population:

```
s <- f_path_allowed(s, allowed[[1]])
```

As a reminder, `s` and `allowed[[1]]` are:

```{r}
# Input to f_path_tx_restrict(), as allowed = f_get_allowed_lists(i, population)
allowed <- output
allowed[[1]]
```

```{r}
# Input to f_path_tx_restrict()
sequences <- i$sequences
s <- sequences
head(s)
```

We apply the function `f_path_allowed()`...

```{r}
f_path_allowed <- function(perms, rule) {
  #objective of function is to identify perms that violate rule and exclude
  cat("applying rule:", rule, "are only allowed treatments.\n")
  cat("Permutations before applying rule:", nrow(perms), "\n")
  
  rule <- c(rule, "BSC", "")
  
  for (n in 1:ncol(perms)) {
    perms <- perms[perms[,n] %in% rule,]
  }
  
  cat("Permutations after applying rule :", nrow(perms),"\n")
  return(perms)
  
}
```

So in this case...

```{r}
perms <- s
rule <- allowed[[1]]

cat("applying rule:", rule, "are only allowed treatments.\n")
cat("Permutations before applying rule:", nrow(perms), "\n")
```

It adds BSC (best supportive care) and an empty element to the list of allowed treatments

```{r}
rule <- c(rule, "BSC", "")
```

It then loops through each of the lines of treatment (columns of `perms` - V1, V2, V3, V4, V5, V6), and only keeps the rows if the treatment in that column in that row is in the list of allowed treatments.

```{r}
for (n in 1:ncol(perms)) {
  perms <- perms[perms[,n] %in% rule,]
}

cat("Permutations after applying rule :", nrow(perms),"\n")
```

```{r}
f_path_allowed(s, allowed[[1]])
```

So, as a whole:

```{r}
for (population in 1:i$i_nr_populations) {
  sequences <- as.data.frame(i$sequences)
  allowed <- f_get_allowed_lists(i, population)
  print(paste0("Dropping drugs not allowed for pop", population))
  sequences
  s <- f_path_allowed(sequences, allowed[[1]])
  s
}
```

:::

::: {.callout-note collapse="true"}

## Explaining the other functions in `f_path_tx_restrict()`

As a reminder, these were:

```
s <- f_path_tx_restrict(
  sequences                = i$sequences,
  allowed                  = f_get_allowed_lists(i, population), #overall list of allowed drugs in this popn
  L1                       = f_get_L1_lists(i, population), # 1L drugs allowed in this popn
  L2                       = f_get_L2_lists(i, population), # 2L drugs allowed in this popn
  L3                       = f_get_L3_lists(i, population), # 3L drugs allowed in this popn
  L4                       = f_get_L4_lists(i, population), # 4L drugs allowed in this popn
  only_after               = f_get_only_after_lists(i, population), #list of restrictions where tx can be only after the listed txs
  not_immediate_after      = f_get_not_immediate_after_lists(i, population), #list of restrictions where tx can be only immediately before the listed txs
  one_in_list              = f_get_one_in_list_lists(i, population), #list of restrictions where only one of the tx in each list is allowed 
  only_after_one           = f_get_only_after_one_lists(i, population), #list of restrictions where only one of the listed treatments is allowed prior to current therapy 
  L2_only_after            = f_get_2L_only_after_lists(i, population), #list of 2L+ restrictions: if drug is used 2L, 3L or 4L, can only be after drug x
  L2_only_immediate_after  = f_get_2L_only_immediate_after_lists(i, population), #list of 2L+ restrictions: if drug is used 2L, 3L or 4L, can only be immediately after drug x
  L2_only_one              = f_get_2L_only_one_lists(i, population) #list of 2L+ drugs where only one of them allowed in a given sequence
)
```

We have functions that find the overall list of allowed drugs for the population, and then the drugs allowed for each line of treatment.

```{r}
print("Overall list of allowed drugs")
f_get_allowed_lists(i, i$i_nr_populations[1])

print("L1")
f_get_L1_lists(i, i$i_nr_populations[1])
print("L2")
f_get_L2_lists(i, i$i_nr_populations[1])
print("L3")
f_get_L3_lists(i, i$i_nr_populations[1])
print("L4")
f_get_L4_lists(i, i$i_nr_populations[1])
```

We then have treatments that can only come after or before certain treatments. As illustrated in Figure 1 in the pathway model report, you can see examples like how:

* Axitinib - can only administer after tyrosine kinase inhibitor (TKI) (e.g. sunitinib) or cytokine
* Everolimus - can only administrater after vascular endothelial growth factor (VEGF)

```{r}
print("list of restrictions where tx can be only after the listed txs")
f_get_only_after_lists(i, i$i_nr_populations[1])

print("list of restrictions where tx can be only immediately before the listed txs")
f_get_not_immediate_after_lists(i, i$i_nr_populations[1])

print("list of restrictions where only one of the tx in each list is allowed ")
f_get_one_in_list_lists(i, i$i_nr_populations[1])

print("list of restrictions where only one of the listed treatments is allowed prior to current therapy ")
f_get_only_after_one_lists(i, i$i_nr_populations[1])

print("list of 2L+ restrictions: if drug is used 2L, 3L or 4L, can only be after drug x")
f_get_2L_only_after_lists(i, i$i_nr_populations[1])

print("list of 2L+ restrictions: if drug is used 2L, 3L or 4L, can only be immediately after drug x")
f_get_2L_only_immediate_after_lists(i, i$i_nr_populations[1])

print("list of 2L+ drugs where only one of them allowed in a given sequence")
f_get_2L_only_one_lists(i, i$i_nr_populations[1])
```

Within `f_path_tx_restrict()`, various functions are then applied to implement the logic of these lists. For example:

* `f_path_drug_lines()` is used to remove drugs from a line unless it is listed in `L1`, `L2`, `L3`, or `L4`.
* For `only_after`, `f_path_notAllowedImmediateAfter()` is used to remove permutations that have treatment before drugs in rule

And so on. Overall, we then get:

```{r}
population <- i$i_nr_populations[1]

s <- f_path_tx_restrict(
  sequences                = i$sequences,
  allowed                  = f_get_allowed_lists(i, population), #overall list of allowed drugs in this popn
  L1                       = f_get_L1_lists(i, population), # 1L drugs allowed in this popn
  L2                       = f_get_L2_lists(i, population), # 2L drugs allowed in this popn
  L3                       = f_get_L3_lists(i, population), # 3L drugs allowed in this popn
  L4                       = f_get_L4_lists(i, population), # 4L drugs allowed in this popn
  only_after               = f_get_only_after_lists(i, population), #list of restrictions where tx can be only after the listed txs
  not_immediate_after      = f_get_not_immediate_after_lists(i, population), #list of restrictions where tx can be only immediately before the listed txs
  one_in_list              = f_get_one_in_list_lists(i, population), #list of restrictions where only one of the tx in each list is allowed 
  only_after_one           = f_get_only_after_one_lists(i, population), #list of restrictions where only one of the listed treatments is allowed prior to current therapy 
  L2_only_after            = f_get_2L_only_after_lists(i, population), #list of 2L+ restrictions: if drug is used 2L, 3L or 4L, can only be after drug x
  L2_only_immediate_after  = f_get_2L_only_immediate_after_lists(i, population), #list of 2L+ restrictions: if drug is used 2L, 3L or 4L, can only be immediately after drug x
  L2_only_one              = f_get_2L_only_one_lists(i, population) #list of 2L+ drugs where only one of them allowed in a given sequence
)
```

:::

```{r}
i$sequences <- seqs
rm(s, seqs, populations)
```

## Import IPD and look-ups

### Import individual patient-level data (IPD) (pseudo/synthetic trial data)

::: {.callout-warning collapse="true"}

Set excel path at start of script instead of here and changed default path

:::

```{r}
i$surv <- list()

if (file.exists(excel_path2)) {
  wb <- f_excel_extract(excel_path2, verbose = TRUE)
  i$surv$pld <- as.data.table(wb$`_xlnm._FilterDatabase`)
  rm(wb)
} else {
  wb <- f_excel_extract(rstudioapi::selectFile(
    caption = "Select the IPD file (IPD_R_input_noACIC.xlsx)",
    label = "IPD_R_input_noACIC.xlsx",
    path = "../1_Data/",
    filter = "Excel Files (*.xlsx)",
    existing = TRUE
  ), verbose = TRUE)
  i$surv$pld <- as.data.table(wb$`_xlnm._FilterDatabase`)
  
}

i$surv$pld <- i$surv$pld[,list(population,line,molecule,trial,endpoint,timew,event_censor)]

i$surv$pld[timew ==0,"timew"] <- 1/7
```

::: {.callout-note collapse="true"}

The file we are importing contains pseudo-individual patient data (IPD) for all the clinical trials (i.e. simulated data to replace clinical trial data considered confidential).

This uses `f_excel_extract()` like before, this time from `IPD_R_input_noACIC.xlsx`. It produces `wb` which is a list with one item: `wb$_xlnm._FilterDatabase`.

```{r}
wb <- f_excel_extract(excel_path2, verbose = TRUE)
length(wb)
```

That is simply the table from the `IPD` sheet of that dataframe.

```{r}
df <- as.data.table(wb$`_xlnm._FilterDatabase`)
dim(df)
head(df)
```

The script then filter to only the columns: `list(population,line,molecule,trial,endpoint,timew,event_censor)`.

Then it finds the rows where the column `timew`==0, and replaces their values with 1/7. In `Model_Structure.R`, they explain that this is because we don't allow zero survival times, so has to be at least 1 day (and since TuotA is in weeks, this is 1/7... not sure what TuotA is).

Looking at what this dataframe contains...

```{r}
unique(df$population)

unique(df$line)

unique(df$molecule)

unique(df$trial)

unique(df$endpoint)

describe(df$timew)

unique(df$event_censor)
```

`molecule`: combination therapies are under same number

`trial`: trial id *within* population line and molecule to set them apart (so often just 1)

`event_censor`: event coded as 1, censor as 0

Final result:

```{r}
head(i$surv$pld)
```

:::

### Get look-ups for each column

```{r}
i$id$ipd <- list(
  pop      = i$r_pld_lookup_pop$Number[!is.na(i$r_pld_lookup_pop$Number)],
  line     = i$r_pld_lookup_line$Number[!is.na(i$r_pld_lookup_line$Number)],
  mol      = i$r_pld_lookup_mol$Number[!is.na(i$r_pld_lookup_mol$Number)],
  trial    = i$r_pld_lookup_trial$Number[!is.na(i$r_pld_lookup_trial$Number)],
  endpoint = i$r_pld_lookup_endpoint$Number[!is.na(i$r_pld_lookup_endpoint$Number)]
)
```

::: {.callout-note collapse="true"}

Gets the unique values from each column (excluding NaN)

```{r}
i$id$ipd
```

:::

```{r}
names(i$id$ipd$pop)      <- paste0("pop_"     , i$id$ipd$pop)
names(i$id$ipd$line)     <- paste0("line_"    , i$id$ipd$line)
names(i$id$ipd$mol)      <- paste0("mol_"     , i$id$ipd$mol)
names(i$id$ipd$trial)    <- paste0("trial_"   , i$id$ipd$trial)
names(i$id$ipd$endpoint) <- paste0("endpoint_", i$id$ipd$endpoint)
```

::: {.callout-note collapse="true"}

Adds names for each which combine the column name with the value

```{r}
i$id$ipd
```

:::

```{r}
i$lookup$ipd <- list(
  pop      = data.table(i$r_pld_lookup_pop)[Description != 0],
  line     = data.table(i$r_pld_lookup_line)[Description != 0],
  mol      = data.table(i$r_pld_lookup_mol)[Description != 0],
  trial    = data.table(i$r_pld_lookup_trial)[Description != 0],
  endpoint = data.table(i$r_pld_lookup_endpoint)[Description != 0]
)
```

::: {.callout-note collapse="true"}

Makes a list containing dataframes with the look-ups for each of those columns (which were stored in `i`).

```{r}
i$lookup$ipd
```

:::

```{r}
i$lookup$ipd$line$seq_col <- paste0("V",2:(nrow(i$lookup$ipd$line)+1))
i$lookup$ipd$line$R_id    <- paste0("line_",1:nrow(i$lookup$ipd$line))
```

::: {.callout-note collapse="true"}

Create a list of V2, V3, V4...

And line_1, line_2, line_3...

For length of the `line` (i.e. 5 long: 1st, 2nd, 3rd or 4th line of treatment, or best supportive care (BSC)),

```{r}
i$lookup$ipd$line$seq_col
i$lookup$ipd$line$R_id
```

:::

```{r}
i$lookup$dist <- i$r_pld_lookup_dist
```

::: {.callout-note collapse="true"}

Save the look up for distributions under `i$lookup$dist` (just making another entry in `i` but under a different name)

```{r}
i$lookup$dist
```

:::

```{r}
i$lookup$trt <- i$lookup$ipd$mol$Number
names(i$lookup$trt) <- i$lookup$ipd$mol$RCC_input_desc
names(i$lookup$trt)[length(i$lookup$trt)] <- "BSC"
```

::: {.callout-note collapse="true"}

Create a treatment lookup but getting the numbers for each molecule, and their equivalent name from `RCC_input_desc`

```{r}
i$lookup$trt
```

:::

## Pre-processing for survival analysis

```{r}
p$basic$lookup <- i$lookup
p$basic$id <- i$id

i$seq_clean <- data.table(i$sequences)
```

::: {.callout-note collapse="true"}

Add look-ups and ids from `i` to `p`

```{r}
p$basic$lookup
p$basic$id
```

Convert sequences to a data table

```{r}
head(i$seq_clean)
```

:::

```{r}
i$seq_clean$V1 <- paste0("pop_",as.numeric(substr(i$seq_clean$V1,4,4)) - 1)
i$seq_pops <- unique(i$seq_clean$V1)
names(i$seq_pops) <- i$seq_pops
```

::: {.callout-note collapse="true"}

Changes `i$seq_clean$V1` from having pop_1 to pop_4, to having pop_0 to pop_3.

```{r}
i$seq_pops
```

:::

```{r}
i$seq_clean <- lapply(i$seq_pops, function(popu) {
  tmp <- i$seq_clean[V1 == popu,-1]
  colnames(tmp) <- i$lookup$ipd$line$R_id[1:(p$basic$R_maxlines + 1)]
  tmp
})
```

::: {.callout-note collapse="true"}

Loops through each of the populations, and then gets the treatment sequences for that population, and saves them under new column names (line_1 to line_5), using the lookup, and saving them as seperate dataframes for each population.

```{r}
i$lookup$ipd$line
```

```{r}
head(i$seq_clean$pop_0)
```

:::

```{r}
i$seq_n <- lapply(i$seq_clean, function(popu) {
  as.data.table(lapply(popu, function(co) i$lookup$trt[co]))
})
```

::: {.callout-note collapse="true"}

Create new item `i$seq_n`. It looks through the four sequence tables in `i$seq_clean`. It then loops through each column in each of those dataframes (i.e. line 1, line 2, line 3...) and uses `i$lookup$trt` to convert from the name of the treatment to the numeric identifier for that treatment.

Look up table:

```{r}
i$lookup$trt
```

Output example:

```{r}
head(i$seq_n$pop_0)
```

:::

```{r}
i$seq_ref <- lapply(i$seq_clean, function(popu) {
  tmp <- as.data.table(lapply(popu, function(co) {
    vals <- paste0("mol_",i$lookup$trt[co])
    ifelse(vals == "mol_NA",NA,vals)
  }))
})
```

::: {.callout-note collapse="true"}

Creates `i$seq_ref`. This just takes the table with the drug in each line of treatment, but instead of just converting it to the number representing each treatment, it adds the mol_ suffix, e.g. mol_4, mol_5

```{r}
head(i$seq_ref$pop_0)
```

:::

```{r}
p$seq$n   <- i$seq_n
p$seq$ref <- i$seq_ref
p$seq$qc <- i$seq_clean
```

```{r}
i$surv$lab_pld <- list()

i$surv$lab_pld$population <- i$lookup$ipd$pop$Number
names(i$surv$lab_pld$population) <- i$lookup$ipd$pop$Description

i$surv$lab_pld$line <- i$lookup$ipd$line$Number
names(i$surv$lab_pld$line) <- i$lookup$ipd$line$Description

i$surv$lab_pld$molecule <- i$lookup$ipd$mol$Number
names(i$surv$lab_pld$molecule) <- i$lookup$ipd$mol$Description

i$surv$lab_pld$trial <- i$lookup$ipd$trial$Number
names(i$surv$lab_pld$trial) <- i$lookup$ipd$trial$Description

i$surv$lab_pld$endpoint <- i$lookup$ipd$endpoint$Number
names(i$surv$lab_pld$endpoint) <- i$lookup$ipd$endpoint$Description
```

::: {.callout-note collapse="true"}

Makes a named list from each of the look ups.

For example it uses these...

```{r}
i$lookup$ipd$pop$Number
i$lookup$ipd$pop$Description
```

...to make this...

```{r}
i$surv$lab_pld$population
```

:::

```{r}
i$surv$lab_pld$dat <- i$surv$pld
i$surv$lab_pld$dat$population <- names(i$surv$lab_pld$population)[match(i$surv$lab_pld$dat$population,i$surv$lab_pld$population)]
i$surv$lab_pld$dat$line       <- names(i$surv$lab_pld$line)[match(i$surv$lab_pld$dat$line,i$surv$lab_pld$line)]
i$surv$lab_pld$dat$molecule   <- names(i$surv$lab_pld$molecule)[match(i$surv$lab_pld$dat$molecule,i$surv$lab_pld$molecule)]
i$surv$lab_pld$dat$trial      <- names(i$surv$lab_pld$trial)[match(i$surv$lab_pld$dat$trial,i$surv$lab_pld$trial)]
i$surv$lab_pld$dat$endpoint   <- names(i$surv$lab_pld$endpoint)[match(i$surv$lab_pld$dat$endpoint,i$surv$lab_pld$endpoint)]
```

::: {.callout-note collapse="true"}

Converts from `i$surv$pld` (which is all numeric values)...

```{r}
head(i$surv$pld)
```

...to a version with all the labels from the lookups...

```{r}
head(i$surv$lab_pld$dat)
```

::: 

```{r}
i$surv$n_by_plmte <- i$surv$pld[, .N, by = list(population, line,molecule,trial,endpoint)] %>%
  arrange(population,line, molecule,trial,endpoint)

i$surv$n_by_plmte$population <- i$lookup$ipd$pop[match(i$surv$n_by_plmte$population       ,i$lookup$ipd$pop$Number),Description]
i$surv$n_by_plmte$line       <- i$lookup$ipd$line[match(i$surv$n_by_plmte$line       ,i$lookup$ipd$line$Number),Description]
i$surv$n_by_plmte$molecule   <- i$lookup$ipd$mol[match(i$surv$n_by_plmte$molecule       ,i$lookup$ipd$mol$Number),Description]
i$surv$n_by_plmte$molecule[which(is.na(i$surv$n_by_plmte$molecule))]   <- "Non-UK treatments (pooled)"
i$surv$n_by_plmte$trial      <- i$lookup$ipd$trial[match(i$surv$n_by_plmte$trial       ,i$lookup$ipd$trial$Number),Description]
i$surv$n_by_plmte$endpoint   <- i$lookup$ipd$endpoint[match(i$surv$n_by_plmte$endpoint       ,i$lookup$ipd$endpoint$Number),Description]
```

::: {.callout-note collapse="true"}

Counts for each combination of pop + line + molecule + trial + endpoint (together, uses abbreviation plmte).

```{r}
head(i$surv$pld[, .N, by = list(population, line,molecule,trial,endpoint)] %>%
  arrange(population,line, molecule,trial,endpoint))
```

Then replaces the numeric values with labels

```{r}
head(i$surv$n_by_plmte)
```

::: 

## Partitioned survival analysis (PartSA)

### Run analysis

```{r}
if (i$dd_run_surv_reg == "Yes") {
  
  i$surv$reg <- f_surv_runAllTSD14(
    r_pld             = i$surv$pld,
    id                = i$id$ipd,
    lookups           = i$lookup$ipd,
    draw_plots        = FALSE,
    distnames         = i$distnames,
    cl_y              = p$basic$cl_y,
    t_cyc             = p$basic$t_cyc,
    xlim_survplots_yr = p$misc$plot$xlim_survplots_yr,
    t_yr              = p$basic$t_yr,
    verbose           = qc_mode,
    min_obs           = 28
  )

  i$surv$reg$pop_0$line_4$mol_999$trial_2$endpoint_4 <- lapply(1:1,function(x) {

    ipd <- i$surv$pld[line==4 & endpoint==4,list(timew,event_censor)]
    
    names(ipd) <- c("t","e")
    
    cat(paste0(
      "Survival analysis - population: ", i$lookup$ipd$pop[Number      == 0, Description],
      "\t line: "                       , i$lookup$ipd$line[Number     == 4, Description],
      "\t molecule: "                   , i$lookup$ipd$mol[Number     == 999, Description],
      "\t trial: "                      , i$lookup$ipd$trial[Number     == 2, Description],
      "\t endpoint: "                   , i$lookup$ipd$endpoint[Number == 4, Description], "\n"
    ))
    
    fs_fits <- lapply(i$distnames, function(dist) {  # applying all parametric survival curves in the list of distNames
      fs_fit <- flexsurvreg(
        formula = Surv(t, e) ~ 1,
        data = ipd,
        dist = dist
      )
      return(list(
        coefs = coefficients(fs_fit),                                         # coefficients for the fitted model
        vcov  = vcov(fs_fit),                                                 # variance covariance matrix for the fitted model
        fit   = c(AIC= AIC(fs_fit), BIC=BIC(fs_fit), logLik = logLik(fs_fit)) # goodness of fit statistics for the fitted model
      ))
    })
    
    gof <- do.call(rbind, lapply(i$distnames, function(dist) fs_fits[[dist]]$fit))
    
    st <- matrix(
      unlist(lapply(i$distnames, function(dist) {
        f_extrapolate(p$basic$t_cyc, fs_fits[[dist]]$coefs, dist)
      })),
      ncol = length(i$distnames),
      dimnames = list(NULL, i$distnames),
      byrow = FALSE
    )

    plot <- {
      
      sm_ipd <- f_ce_km_MakeDatSurvFriendly(
        Data_required = ipd,
        time_column   = "t",                 # note that this is taking IPD in weeks
        event_column  = "e",
        t_multiplier  = p$basic$cl_y             # data in weeks, cycle length in plot years
      )
      
      form          <- Surv(t, ec) ~ 1
      sm_surv_est   <- surv_fit(formula = form, data = sm_ipd)
      
      survival_plot <- suppressMessages(f_extrap_plot(
        SurvEstimate   = sm_surv_est,
        Data_required  = sm_ipd,
        curvefits_data = st,
        time_vector    = p$basic$t_yr,
        xlim           = p$misc$plot$xlim_survplots_yr,   #### this will need replacing dependent on how many years we decide to show per time horizon
        break_by       = round(20/8,0) #### this will need replacing dependent on how many years we decide to show per time horizon
      ))
      list(
        ipd     = sm_ipd,
        formula = form,
        plot    = survival_plot
      )
    }

    return(list(
      pop      = i$lookup$ipd$pop[     Number == 0,Description],
      line     = i$lookup$ipd$line[    Number == 4,Description],
      mol      = i$lookup$ipd$mol[     Number == 999,Description],
      tr       = i$lookup$ipd$trial[     Number == 2,Description],
      endpoint = i$lookup$ipd$endpoint[Number == 4,Description],
      ipd      = ipd,
      fs_fits  = fs_fits,
      gof      = gof,
      st       = st,
      plot     = plot
    ))
  })[[1]]
  
  saveRDS(i$surv$reg, file = "./1_Data/Survival_analysis.rds")
  
}
```

::: {.callout-note collapse="true"}

This was not run as is set to "No" in the excel spreadsheet

```{r}
i$dd_run_surv_reg
```

However, if run, this function would:

**1. Run survival analysis**. Using `f_surv_runAllTSD14()` from `survival/` (see dropdown below). "TSD14" refers to technical support document 14 which is a methods guide from NICE for performing survival analysis, [available here](https://www.sheffield.ac.uk/nice-dsu/tsds/survival-analysis). The function;

* Runs through all possible populations, lines, molecules, trials and endpoints in `id` (`i$id$ipd`, the lookup of unique values for each of those items)
* If there is data available in `r_pld` (`i$surv$pld`, the patient level data), then it performs survival analysis using the function `flexsurv::flexsurvreg()`. This data will need to meet the threshold you set for the number of observations (default `28`).
* It repeats this for each with each of the distributions in `distnames`
* It saves the coefficients, variance covariance matrix, and goodness of fit statistics, and saves these as `fs_fits` (and also `gof`)
* The survival curves are then extrapolated using the fitted models over the specified time cycle (`t_cyc` (`p$basic$t_cyc`)) using the function `f_extrapolate()`. These are saved in the matrix `st` (survival at time t, or st for short)
* If creating plots, this is done using the function `f_extrap_plot()`
* Finally, the function returns the results for each combination

**2. Seperately, manually run survival analysis for best supportive care (BSC)**. This is done seperately as there is very little information available on BSC overall survival (OS). Hence, the best source of data is to use the pooled post-progression survival (PPS) data from 4L (fourth line) patients (since they are unlikely to receive something after that treatment). It has similar steps to `f_surv_runAllTSD14()`.

::: 

::: {.callout-note collapse="true"}

## `f_surv_runAllTSD14()`

```{r}
f_surv_runAllTSD14 <-
  function(r_pld,
           id,
           lookups,
           distnames,
           t_cyc,
           cl_y              = NULL,
           xlim_survplots_yr = NULL,
           t_yr              = NULL,
           draw_plots        = FALSE,
           verbose           = FALSE,
           min_obs           = 30) {
    
    if (draw_plots) {
      if(is.null(cl_y)) stop("If draw_plots is TRUE, then cl_y (cycle length in years) must be provided")
      if(is.null(xlim_survplots_yr)) stop("If draw_plots is TRUE, then xlim_survplots_yr (x axis limit for plot in years) must be provided")
      if(is.null(t_yr)) stop("If draw_plots is TRUE, then t_yr (vector of time in years to TH) must be provided")
    }
    
    
  lapply(id$pop, function(trial_population) {
    lapply(id$line, function(l) {
      lapply(id$mol, function(m) {
        lapply(id$trial, function(tr) {
          lapply(id$endpoint, function(en) {
            
            
            # Filter down to the parameters avove associated with this combination:
            ipd <- r_pld[population == trial_population & line==l & molecule==m & trial==tr & endpoint==en,list(timew,event_censor)]
            
            names(ipd) <- c("t","e")
            
            if(all(verbose, nrow(ipd) > 0)) {
              cat(paste0(
                "Survival analysis - population: ", lookups$pop[Number      == trial_population, Description],
                "\t line: "                       , lookups$line[Number     == l               , Description],
                "\t molecule: "                   , lookups$mol[Number      == m               , Description],
                "\t trial: "                      , tr,
                "\t endpoint: "                   , lookups$endpoint[Number == en              , Description], "\n"
              ))
            }
            
            
            # If that dataset is empty (i.e., has no rows), then there's no data for it. return
            # nothing
            if (nrow(ipd) == 0) {
              return(list(
                pop      = lookups$pop[     Number == trial_population,Description],
                line     = lookups$line[    Number == l,Description],
                mol      = lookups$mol[     Number == m,Description],
                tr       = lookups$trial[     Number == tr,Description],
                endpoint = lookups$endpoint[Number == en,Description],
                ipd      = NULL,
                fs_fits  = NULL,
                gof      = NULL,
                st       = NULL,
                plot     = NULL
              ))
            } else if (nrow(ipd) < min_obs) {
              
              warning(paste0(
                lookups$pop[Number      == trial_population, Description],
                " population "     , lookups$line[Number     == l               , Description],
                " " , lookups$mol[Number      == m               , Description],
                " " , lookups$endpoint[Number == en              , Description],
                " from "    , lookups$trial[Number == tr              , Description],
                " has ",nrow(ipd), "(<", min_obs, ") observations (i.e. < the minimum set by you!). Skipping this PLMTE."
              ),immediate. = TRUE)
              
              return(list(
                pop      = lookups$pop[     Number == trial_population,Description],
                line     = lookups$line[    Number == l,Description],
                mol      = lookups$mol[     Number == m,Description],
                tr       = lookups$trial[     Number == tr,Description],
                endpoint = lookups$endpoint[Number == en,Description],
                ipd      = NULL,
                fs_fits  = NULL,
                gof      = NULL,
                st       = NULL,
                plot     = NULL
              ))
              
              
            } else {
              
              # If there IS data, continue on to use that data to produce full survival analysis results.
              # 
              # Remember that the IPD is sensitive so should not ever be saved to disk. Being stored in i
              # and never saved is the way to do this.
              
              # Even within the multiple nesting by population, line, molecule, trial and endpoint,
              # we need ANOTHER (6th) layer - the parametric model:
              
              
              
              
              
              
              fs_fits <- lapply(distnames, function(dist) {  # applying all parametric survival curves in the list of distNames
                fs_fit <- flexsurvreg(
                  formula = Surv(t, e) ~ 1,
                  data = ipd,
                  dist = dist
                )
                return(list(
                  coefs = coefficients(fs_fit),                                         # coefficients for the fitted model
                  vcov  = vcov(fs_fit),                                                 # variance covariance matrix for the fitted model
                  fit   = c(AIC= AIC(fs_fit), BIC=BIC(fs_fit), logLik = logLik(fs_fit)) # goodness of fit statistics for the fitted model
                ))
              })
              
              gof <- do.call(rbind, lapply(distnames, function(dist) fs_fits[[dist]]$fit))
              
             
              st <- matrix(
                unlist(lapply(distnames, function(dist) {
                  f_extrapolate(t_cyc, fs_fits[[dist]]$coefs, dist)
                })),
                ncol = length(distnames),
                dimnames = list(NULL, distnames),
                byrow = FALSE
              )
              
              if (draw_plots) {
                
                plot <- {
                  # First the IPD is produced in a format that survminer will accept. Data must all be 
                  # the same format with the same column names. 
                  # this assumes no covariate adjustment.
                  
                  sm_ipd <- f_ce_km_MakeDatSurvFriendly(
                    Data_required = ipd,
                    time_column   = "t",                 # note that this is taking IPD in weeks 
                    event_column  = "e",
                    t_multiplier  = cl_y             # data in weeks, cycle length in plot years
                  )
                  
                  # get the survival analysis in the form we need for survminer
                  # and make the extrapolations we need for survminer
                  
                  form          <- Surv(t, ec) ~ 1
                  sm_surv_est   <- surv_fit(formula = form, data = sm_ipd)
                  
                  # make the plot with the input data:
                  survival_plot <- suppressMessages(f_extrap_plot(
                    SurvEstimate   = sm_surv_est,
                    Data_required  = sm_ipd,
                    curvefits_data = st,
                    time_vector    = t_yr,
                    xlim           = xlim_survplots_yr,   
                    break_by       = round(xlim_survplots_yr/8,0) 
                  ))
                  list(
                    ipd     = sm_ipd,
                    formula = form,
                    plot    = survival_plot
                  )
                }
              } else {
                plot <- NULL
              }
              
              # Now that we've done everything for this dataset, return a list of the stuff
              # we need for it:
              return(list(
                pop      = lookups$pop[     Number == trial_population,Description],
                line     = lookups$line[    Number == l,Description],
                mol      = lookups$mol[     Number == m,Description],
                tr       = lookups$trial[     Number == tr,Description],
                endpoint = lookups$endpoint[Number == en,Description],
                ipd      = ipd,
                fs_fits  = fs_fits,
                gof      = gof,
                st       = st,
                plot     = plot
              ))
            }
          })
        })
      })
    })
  })
}
```

:::

### Load pre-run survival analysis

::: {.callout-warning collapse="true"}

Set file path at start and changed default path here

::: 

```{r}
if (file.exists(RDS_path)) {
  i$surv$reg <- readRDS(RDS_path)
} else {
  i$surv$reg <- readRDS(rstudioapi::selectFile(
    caption = "Please select 'Survival_analysis_noTTDorTTPorPPS[NoACIC].rds'",
    label = "Survival_analysis_noTTDorTTPorPPS[NoACIC].rds",
    path = "../1_Data/",
    filter = "R Files (*.rds)",
    existing = TRUE
  ))
}
```

::: {.callout-note collapse="true"}

Looking at some examples...

```{r}
i$surv$reg$pop_0$line_1$mol_0$trial_0$endpoint_0
```

```{r}
i$surv$reg$pop_2$line_1$mol_4$trial_2$endpoint_1$pop
i$surv$reg$pop_2$line_1$mol_4$trial_2$endpoint_1$line
i$surv$reg$pop_2$line_1$mol_4$trial_2$endpoint_1$mol
i$surv$reg$pop_2$line_1$mol_4$trial_2$endpoint_1$tr
i$surv$reg$pop_2$line_1$mol_4$trial_2$endpoint_1$endpoint
i$surv$reg$pop_2$line_1$mol_4$trial_2$endpoint_1$fs_fits
i$surv$reg$pop_2$line_1$mol_4$trial_2$endpoint_1$gof
head(i$surv$reg$pop_2$line_1$mol_4$trial_2$endpoint_1$st)
i$surv$reg$pop_2$line_1$mol_4$trial_2$endpoint_1$plot
```

::: 

```{r}
TH <- p$basic$th + 1

i$surv$reg <-lapply(i$surv$reg, function(popu) {
  lapply(popu, function(li) {
    lapply(li, function(mol) {
      lapply(mol, function(tr) {
        lapply(tr, function(endp) {
          if (is.null(endp$st)) {
            return(endp)
          } else {
            endp$st <- endp$st[1:TH,]
            return(endp)
          }
        })
      })
    })
  })
})
```

::: {.callout-note collapse="true"}

Limits the matrix with the extrapolated survival curves to the time horizon of the study

```{r}
TH
```

:::

### Make survival analysis report

::: {.callout-warning collapse="true"}

I've changed path to doc below.

:::

```{r}
if (i$dd_report_req_surv_reg=="Yes") {
  
  doc_surv <- f_surv_makeTSD14Report(
    fs_res = i$surv$reg,
    id     = i$id$ipd,
    lookup = i$lookup$ipd
  )
  print(doc_surv, target = "../4_Output/Survival_Analysis.docx")
  
  rm(doc_surv)
}
```

::: {.callout-note collapse="true"}

This only works if you have produced the plots. As our pre-run `.rds` results do not include these, we cannot make the plot. I've tried to run the survival analysis function, but couldn't as hit an error:

```
Error in optim(method = "BFGS", par = c(mu = 5.82584217367559, sigma = -0.208272130470619,  : 
  non-finite finite-difference value [1]
```

:::

## Load results from network meta analysis

::: {.callout-warning collapse="true"}

File path above now, and path option below is changed.

:::

```{r}
if (file.exists(RDS_path2)) {
  i$PHNMA <- readRDS(RDS_path2)
} else {
  i$PHNMA <- readRDS(rstudioapi::selectFile(
    caption = "Please select 'PH_NMA_CODA.rds'",
    label = "PH_NMA_CODA.rds",
    path = "../1_Data/",
    filter = "R Files (*.rds)",
    existing = TRUE
  ))
}

colnames(i$PHNMA$data) <- c("Run", "Population", "Line", "Molecule", "Endpoint", "Reference.treatment", "Reference.trial", "HR")
i$PHNMA$data$Reference.endpoint <- i$PHNMA$data$Endpoint
```

::: {.callout-note collapse="true"}

PH NMA CODA samples. My understanding is that these are "CODA" samples as they are from a Bayesian network meta analysis. "CODA" refers to "Convergence Diagnosis and Output Analysis". When you run a Bayesian analysis, CODA samples are samples from the posterior distribution of your model parameters, as these samples are used to estimate the parameter distributions, check convergence and perform diagnostics.

Imports dataframe, sets colnames, and makes duplicate of `Endpoint` called `Reference.endpoint`.

```{r}
print(head(i$PHNMA$data))
print(dim(i$PHNMA$data))
print(unique(i$PHNMA$data$Endpoint))
```

:::

```{r}
i$PHNMA$assume3L      <- i$PHNMA$data[Line==2,]
i$PHNMA$assume3L$Line <- 3
i$PHNMA$data         <- rbind(i$PHNMA$data,i$PHNMA$assume3L)

i$PHNMA$assumeTTD <- i$PHNMA$data[Endpoint==1,]
i$PHNMA$assumeTTD$Endpoint <- 2
i$PHNMA$data <- rbind(i$PHNMA$data,i$PHNMA$assumeTTD)

i$PHNMA$assumeTTP <- i$PHNMA$data[Endpoint==1,]
i$PHNMA$assumeTTP$Endpoint <- 3
i$PHNMA$data <- rbind(i$PHNMA$data,i$PHNMA$assumeTTP)
```

::: {.callout-note collapse="true"}

`Model_Structure.R` highlights 3L relative effectiveness is assumed to be the same as 2L.

In the code, we can see that it:

* Sets data for 3L (`assume3L`) to `i$PHNMA$data[Line==2,]`
* Sets time to discontinuation (TTD) for 2L to `i$PHNMA$data[Endpoint==1,]`
* Sets time to progression (TTP) for 3L to ` i$PHNMA$data[Endpoint==1,]`

e.g.

```{r}
head(i$PHNMA$assume3L)
head(i$PHNMA$data[Line==2,])
```

:::

```{r}
i$PHNMA$means <- i$PHNMA$data[,.(HR = mean(HR)),by=list(Population,Line,Molecule,Endpoint,Reference.treatment,Reference.trial)]

p$releff$CODA$PH <- i$PHNMA$means
```

::: {.callout-note collapse="true"}

Mean hazard ratio by each combination of population, line, molecule, endpoint, reference treatment and reference trial. `Model_Structure.R` says this is for the deterministic analysis.

```{r}
head(i$PHNMA$means)
```

```{r}
dim(i$PHNMA$data)

# Find the number of hazard ratios per group, used when finding means
# and we see that, for each one, it is 10000
phnma_group_n <- i$PHNMA$data[, .(Number_of_Rows = .N), by = list(Population, Line, Molecule, Endpoint, Reference.treatment, Reference.trial)]
unique(phnma_group_n$Number_of_Rows)
```

:::

::: {.callout-warning collapse="true"}

File path above now, and path option below is changed.

:::

```{r}
i$FPNMA <- list()

if (file.exists(RDS_path3)) {
  i$FPNMA$means  <- readRDS(RDS_path3)
} else {
  i$FPNMA$means <- readRDS(rstudioapi::selectFile(
    caption = "Load in FP NMA CODA (FPNMA_means.rds)",
    label = "FPNMA_means.rds",
    path = "../1_Data/",
    filter = "R Files (*.rds)",
    existing = TRUE
  ))
}

colnames(i$FPNMA$means)[colnames(i$FPNMA$means) == "intervention_code"] <- "Molecule"
colnames(i$FPNMA$means)[colnames(i$FPNMA$means) == "reference_treatment_code"] <- "Reference.treatment"
colnames(i$FPNMA$means)[colnames(i$FPNMA$means) == "ref_trial_code"] <- "Reference.trial"
colnames(i$FPNMA$means)[colnames(i$FPNMA$means) == "population"] <- "Population"
colnames(i$FPNMA$means)[colnames(i$FPNMA$means) == "line"] <- "Line"
colnames(i$FPNMA$means)[colnames(i$FPNMA$means) == "endpoint"] <- "Endpoint"
colnames(i$FPNMA$means)[colnames(i$FPNMA$means) == "V1"] <- "HR"

i$FPNMA$means$time <- round(i$FPNMA$means$time * 52 / 12)
```

::: {.callout-note collapse="true"}

Import fractional polynomial (FP) NMA data.

Rename columns and convert time to months (as multiplied by 52, which is the number of weeks in a year, and then divides by 12, which is the number of months). Hence, it seems the original unit was something per week.

```{r}
dim(i$FPNMA$means)
head(i$FPNMA$means)
```

::: 

```{r}
i$FPNMA$means <- f_rebase_for_cabo_as_ref_in_2L(FPNMAdata = i$FPNMA$means)
i$FPNMA$means <- f_3L_rel_effect_same_as_2L(FPNMAdata = i$FPNMA$means) 
i$FPNMA$destinations <- f_gen_destinations(fp_data = i$FPNMA$means)
i$FPNMA$means <- f_add_reference_trial_2(fp_data = i$FPNMA$means)
```

::: {.callout-note collapse="true"}

`misc`: `f_rebase_for_cabo_as_ref_in_2L`: Here, rebasing refers to changing the reference point - in this case, it changes the hazard ratios from molecule 10 in second line to molecule 8 (cabo), to allow the use of cabo as a reference treatment in second line. Joins to end of dataframe.

`misc`: `f_3L_rel_effect_same_as_2L`: Assume that hazard ratios for 3L are same as 2L (like above). Joins to end of dataframe.

`misc`: `f_gen_destinations`: Gets unique combinations of population + line + molecule + endpoint + reference treatment + reference trial. It then duplicates the dataframe and joins the two, except changing that second one so that reference.trial is set for 2 (real-world evidence) on all rows. The function docstrings explains that "this is an assumption of the specific adaptation for the RCC PATT model, which may not hold in other circumstances. Consequently, this function is specific to the RCC model and not the generic pathway"

```{r}
dim(i$FPNMA$destinations)
head(i$FPNMA$destinations)
```

`misc`: `f_add_reference_trial_2`: Makes a copy of `i$FPNMA$means` where reference trial is set to 2. Joins to end of dataframe.

```{r}
unique(i$FPNMA$means$Reference.trial)
i$lookup$ipd$trial
```

:::

```{r}
p$releff$CODA$FP <- i$FPNMA$means
p$releff$fp_dest <- i$FPNMA$destinations[!is.na(Molecule), ]
p$releff$CODA$FP <- p$releff$CODA$FP[time <= p$basic$th, ]
p$releff$fp_dest <- i$FPNMA$destinations[!is.na(Molecule), ]
```

::: {.callout-note collapse="true"}

Add parameters to `p`, remove molecules with NA, and limit time horizon to `p$basic$th`

```{r}
p$basic$th
```

:::

## Relative efficacy network

A relative efficacy network is required to compute the survival times for all the different PLMTEs we need to power the model with.

```{r}
p$releff$network <- f_NMA_generateNetwork(i$id$ipd,i$lookup$ipd)
```

::: {.callout-note collapse="true"}

Uses `survival` function `f_NMA_generateNetwork()` which uses the unique values for population line molecule trial endpoint (accepts labels as input too but these aren't used by the function).

Creates a nested list where can then breakdown by population > line > molecule > trial > endpoint (PLMTE). There is then:

* `$dest` - which holds the numbers for the PLMTE
* `$orig` - empty list of PLMTE plus dist and source
* `$hr` - set to 1
* `$fp` - empty list

```{r}
p$releff$network$pop_0$line_1$mol_0$trial_0$endpoint_0
```

:::

```{r}
if(!"Trial" %in% colnames(i$R_table_eff_data_settings)) {
  i$R_table_eff_data_settings$Trial <- i$lookup$ipd$trial$Number[match(i$R_table_eff_data_settings$Trial.name.if.effectiveness.source.is.trial,i$lookup$ipd$trial$Description)]
}
```

::: {.callout-note collapse="true"}

If `Trial` is not in `i$R_table_eff_data_settings` (which it wasn't in the default settings) then it gets trial names (`i$R_table_eff_data_settings$Trial.name.if.effectiveness.source.is.trial`)...

```{r}
head(i$R_table_eff_data_settings$Trial.name.if.effectiveness.source.is.trial, 50)
```

...checks if they are in the lookup (`i$lookup$ipd$trial$Description`)...

```{r}
i$lookup$ipd$trial$Description
```

... and converts them to trial numbers using another lookup `i$lookup$ipd$trial$Number`

```{r}
i$lookup$ipd$trial$Number
head(i$R_table_eff_data_settings$Trial, 50)
```

:::

```{r}
p$releff$network <- f_NMA_linkPHNMA(
  network       = p$releff$network,
  hr_table      = p$releff$CODA$PH
)
```

::: {.callout-note collapse="true"}

Takes the hazard ratios from `p$releff$CODA$PH` and inputs them into `p$releff$network`

```{r}
head(p$releff$CODA$PH)
```

Looking at example from first row of table, you can see it has populated `hr` and `orig` using `p$releff$CODA$PH`. For example:

* `Molecule` in PHNMA data becomes `dest$mol` in network (as in NMA, destination is treatment being evaluated against reference treatment)
* `Reference.treatment` in PHNMA data becomes `orig$mol` in network (as in NMA, origin is reference treatment)

```{r}
p$releff$network$pop_0$line_1$mol_4$trial_0$endpoint_0
```

Then `Model_Structure.R` has this commented line of code to view all treatments in the network:

```{r}
unique(c(unique(p$releff$means$Molecule),unique(p$releff$means$Reference.treatment),unique(i$R_table_eff_data_settings$Origin.treatment),unique(i$R_table_eff_data_settings$Treatment)))
```

:::

```{r}
p$releff$network <- f_NMA_linkFPNMA(
  network       = p$releff$network,
  destinations  = p$releff$fp_dest,
  hr_table      = p$releff$CODA$FP,
  time_horizon  = p$basic$th
)
```

::: {.callout-note collapse="true"}

This adds the results from `p$releff$CODA$FP` to `$fp$HR` in the network.

This matches up to those from before, this time just adding `$fp$HR` from the FPNMA data.

The example from below is shown, filtering just to `$fp$HR`. You can see this is long, containing 2089 HR.

```{r}
fp_example <- p$releff$network$pop_0$line_1$mol_4$trial_0$endpoint_0$fp$HR
length(fp_example)
head(fp_example, 50)
```

**Why does PHNMA have one HR and FPNMA have loads?**

* PH: Cox proportional hazards model has the "proportional hazards" assumption, which is that we assume the hazard ratio to be constant over time, and so we get a single hazard ratio when comparing two treatments
* FP: Fractional polynomial models have mode flexibility and allow the hazard ratio to vary over time, reflecting how the relative risk between treatments might vary throughout the study period

:::

```{r}
if (i$dd_use_PHnma_for_FPnma == "Yes") {
  i$which_fpnma <- which(i$R_table_eff_data_settings$Effectiveness.data.source == "FP_NMA")
  i$R_table_eff_data_settings$Effectiveness.data.source[i$which_fpnma] <- "PH_NMA"
}
```

::: {.callout-note collapse="true"}

If the setting `dd_use_PHnma_for_FPnma` was set to "Yes" in the excel spreadsheet, then it will identify cases where `i$R_table_eff_data_settings$Effectiveness.data.source == "FP_NMA"` and replace it with `PH_NMA`. In `Model_Strcuture.py`, it explains that this will **force the model to use the PH NMA CODA sample** instead of FP NMA. By default though, this is currently set to "No".

```{r}
i$dd_use_PHnma_for_FPnma
table(i$R_table_eff_data_settings$Effectiveness.data.source)
```

:::

::: {.callout-note collapse="true"}

Saving some examples to use below, so you can see what changes before and after running `f_NMA_AddAssumptionsToNetwork()`...

```{r}
example_trial <- p$releff$network$pop_1$line_1$mol_7$trial_2$endpoint_0
example_fp1 <- head(p$releff$network$pop_1$line_1$mol_1$trial_0$endpoint_0$fp$HR, 10)
example_fp2 <- head(p$releff$network$pop_1$line_1$mol_1$trial_2$endpoint_0$fp$HR, 10)
example_ph1 <- p$releff$network$pop_2$line_1$mol_1$trial_0$endpoint_0$hr
example_ph2 <- p$releff$network$pop_2$line_1$mol_1$trial_2$endpoint_0$hr
example_et <- p$releff$network$pop_1$line_1$mol_5$trial_1$endpoint_0$hr
example_ahr <- p$releff$network$pop_0$line_3$mol_0$trial_2$endpoint_2$hr
```

:::

```{r}
p$releff$network <- f_NMA_AddAssumptionsToNetwork(
  network            = p$releff$network,
  phnma_table        = p$releff$CODA$PH,
  fpnma_table        = p$releff$CODA$FP,
  fpnma_destinations = p$releff$fp_dest,
  excel_table        = data.table(i$R_table_eff_data_settings),
  trial_flag         = i$List_eff_datasources[1],
  fpnma_flag         = i$List_eff_datasources[3],
  phnma_flag         = i$List_eff_datasources[2],
  et_flag            = i$List_eff_datasources[4],
  ahr_flag           = i$List_eff_datasources[5],
  verbose            = qc_mode
)
```

::: {.callout-note collapse="true"}

This function adds "assumption-based" hazard ratios (HRs). It looks at `$Effectiveness.data.source`...

```{r}
table(i$R_table_eff_data_settings$Effectiveness.data.source)
```

And checks if it matches one of the "flags" in `i$List_eff_datasources`. Each of the five flags are explained below...

**Trial flag** - `Trial survival analysis`

This is a reference curve. It is based directly on patient-level data. The origin is the same as the destination. Just seems to ensure origin and destination match, and populate with some info from excel (e.g. dist, source, setting fp to empty list). The `fp` list is empty as it is based on trial data with a fixed curve fit, and there's no need for the fractional polynomial element.

```{r}
# Before f_NMA_AddAssumptionsToNetwork()
example_trial

# After f_NMA_AddAssumptionsToNetwork()
p$releff$network$pop_1$line_1$mol_7$trial_2$endpoint_0
```

**FPNMA flag** - `FP_NMA`

As I've understood it, this populates the hazard ratio for a given comparison using the FP HR from the same comparison in a different trial - so, even though the HR data has come from a different context (different trial), we are saying it is still applicable to this treatment comparison.

**PHNMA flag** - `PH_NMA`

Same as FPNMA, but using the PH HR.

```{r}
# Before f_NMA_AddAssumptionsToNetwork()
example_ph1
example_ph2

# After f_NMA_AddAssumptionsToNetwork()
p$releff$network$pop_2$line_1$mol_1$trial_0$endpoint_0$hr
p$releff$network$pop_2$line_1$mol_1$trial_2$endpoint_0$hr
```

**ET flag** - `Assume equal to`

This assumes the treatments are equal, so sets the HR to 1.

**AHR flag** - `Apply HR to`

Puts in the HR from the Excel sheet column `HR.to.apply`.

I'm not certain if these are definitely the two matching parts (as quite a few get set to 1.19), but as an example...

```{r}
as.list(data.table(i$R_table_eff_data_settings)[309,])
```

```{r}
# Before f_NMA_AddAssumptionsToNetwork()
example_ahr

# After f_NMA_AddAssumptionsToNetwork()
p$releff$network$pop_0$line_3$mol_0$trial_2$endpoint_2$hr
```

```{r}
p$releff$network$pop_0$line_3$mol_0$trial_2$endpoint_2$hr
```

:::

## Survival times

```{r}
i$surv$extraps <- f_surv_getExtrapolations(regs = i$surv$reg)
```

::: {.callout-note collapse="true"}

Creates `i$surv$extraps`, which is a copy of `st` (survival at time t, or st for short) from each PLMTE in `i$surv$reg`.

Two examples below...

```{r}
head(i$surv$reg$pop_0$line_1$mol_1$trial_0$endpoint_3$st)
head(i$surv$extraps$pop_0$line_1$mol_1$trial_0$endpoint_3)
```

```{r}
i$surv$reg$pop_0$line_1$mol_0$trial_0$endpoint_0$st
i$surv$extraps$pop_0$line_1$mol_0$trial_0$endpoint_0
```

:::

```{r}
p$surv$st <- f_releff_PropNetwork(
  network = p$releff$network,
  extraps = i$surv$extraps,
  dos     = 10,
  verbose = qc_mode,
  dist_lookups = p$basic$lookup$dist,
  excel_table = data.table(i$R_table_eff_data_settings)
)
```

::: {.callout-note collapse="true"}

For extrapolations not informed by NMA or assumptions, this function applies the chosen HR to the survival data, in order to extend the survival data (i.e. extrapolate it).

:::

```{r}
if(i$dd_adjforprioradjuvant == "Yes") {
  p$surv$st <- f_surv_adjuvant_HR(
    st              = p$surv$st,
    adjuvant_impact = i$R_table_prior_IO_impact_eff,
    demo_table      = p$demo$table,
    lookup          = p$basic$lookup,
    verbose         = TRUE)
}
```

::: {.callout-note collapse="true"}

Not run in default case...

```{r}
i$dd_adjforprioradjuvant
```

But it applies hazard ratios to the survival data to account for the impact of prior adjuvant treatments. An adjuvant treatment is an additional treatment given alongside the primary treatment.

```{r}
i$R_table_prior_IO_impact_eff
```

:::

```{r}
i$R_table_ptchar <- data.table(i$R_table_ptchar)

if (sum(i$R_table_TE_waning_settings$apply.waning == "Yes") > 0) {
  p$surv$st <- f_surv_twaning_apply(
    st_list     = p$surv$st,
    tab_waning  = data.table(i$R_table_TE_waning_settings),
    tab_eff_set = data.table(i$R_table_eff_data_settings),
    verbose     = qc_mode
  )
}
```

::: {.callout-note collapse="true"}

The function applies treatment effect waning to all PLMTes according to the table provided in the excel inputs...

```{r}
i$R_table_TE_waning_settings[i$R_table_TE_waning_settings$apply.waning == "Yes",]
```

It uses the function `treatment_effect_waning_with_absolute()` to apply treatment effect waning, which refers to the loss of a treatment's benefits over time. It is provided with the cycle in which the treatment effect begins and finishes to wane.

:::

```{r}
p$surv$gpop <- if (i$dd_age_sex_source == "Mean") f_surv_GenOSLines_det(
  R_table_ptchar         = i$R_table_ptchar,
  R_table_mort_lifeTable = i$R_table_mort_lifeTable,
  t_yr                   = p$basic$t_yr,
  lookups                = i$lookup
) else f_surv_GenOSLines_ipd(
  R_table_patientagesex  = i$R_table_patientagesex,
  R_table_mort_lifeTable = i$R_table_mort_lifeTable,
  t_yr                   = p$basic$t_yr,
  lookups                = i$lookup
)
```

::: {.callout-note collapse="true"}

This section calculate the survival curves for the general population, for the overall survival endpoint, for each population and line. It uses two functions:

* `f_surv_GenOSLines_det()` - calculates curves based on characteristics provided in a table
* `f_surv_GenOSLines_ipd()` - calculates curves based on individual patient data

```{r}
p$surv$gpop$pop_0$line_1$d
head(p$surv$gpop$pop_0$line_1$os, 10)
```

In this case:

```{r}
i$dd_age_sex_source 
```

Hence using:

```{r}
head(i$R_table_patientagesex, 10)
```

However, if it were to use means, it would use data from:

```{r}
i$R_table_ptchar
```

:::

```{r}
if (qc_mode) {
  i$gpop <- list(
    means = f_surv_GenOSLines_det(
      R_table_ptchar         = i$R_table_ptchar,
      R_table_mort_lifeTable = i$R_table_mort_lifeTable,
      t_yr                   = p$basic$t_yr,
      lookups                = i$lookup
    ),
    ipd = f_surv_GenOSLines_ipd(
      R_table_patientagesex  = i$R_table_patientagesex,
      R_table_mort_lifeTable = i$R_table_mort_lifeTable,
      t_yr                   = p$basic$t_yr,
      lookups                = i$lookup
    )
  )
  
  i$gpop$plotdat <- data.table(
    t = rep(p$basic$t_yr,2),
    os = c(i$gpop$means$pop_0$line_1$os,i$gpop$ipd$pop_0$line_1$os),
    method = c(rep("Means",p$basic$th+1),rep("Patient data",p$basic$th+1))
  )
  
  i$gpop$comp_plot <- ggplot(i$gpop$plotdat, aes(x = t, y = os, colour = method)) + 
    geom_line() + 
    theme_classic() +
    theme(legend.position = "bottom", legend.title=element_blank()) + 
    labs(title = NULL, x = "Time (years)", y = "% Survival") + 
    scale_x_continuous(expand = expansion(mult = c(0,0.05))) + 
    scale_y_continuous(labels = scales::percent)
  
  if(qc_mode) {
    ggsave(
      filename = file.path("./4_Output/","gpop_1L_method_comparison.png"),
      plot = i$gpop$comp_plot,
      device = "png",
      units = "cm",
      width = 15
    )
  }
}
```

::: {.callout-note collapse="true"}

This is not currently run...

```{r}
qc_mode
```

But if it were, it would compare the general population curves calculation from provided parameters (means) versus from individual patient data.

:::

```{r}
p$surv$st <- f_surv_gpopadjust(st      = p$surv$st,
                               gpop    = p$surv$gpop,
                               method  = "hazardmax",
                               verbose = qc_mode)
```

::: {.callout-note collapse="true"}

This function adjusts the survival curves based on the general population survival curves. This is necessary as we are comparing outcomes from more than two comparison groups, and so we want to control for any imbalance in confounders between the different groups.

:::

```{r}
p$surv$st <- f_surv_PFSxOS(p$surv$st, if(i$dd_adj_cross_curves == "Use hazards"){"hazardmax"} else{"abs"})

p$surv$st <- f_surv_TTDxOS(p$surv$st, if(i$dd_adj_cross_curves == "Use hazards"){"hazardmax"} else{"abs"})

p$surv$st <- f_surv_PFSxTTP(st = p$surv$st,method =  "abs")
```

::: {.callout-note collapse="true"}

These functions check that the following curves don't cross:

* Progression-free survival (PFS) and overall survival (OS) (`f_surv_PFSxOS`)
* Time to discontinuation (TTD) and overall survival (OS) (`f_surv_TTDxOS`)
* Progression-free survival (PFS) and time to progression (TTP) (`f_surv_PFSxTTP`)

To prevent overlap, the first two use `f_surv_hazardmax()`, which ensures the hazard rate is at least as high as the corresponding hazard in the reference curve. This ensures that:

* PFS < OS
* TTD < OS

The final one uses `f_surv_hazardmin()` which ensure that the hazard rate is no greater than the corresponding hazard in the reference curve, to ensure a minimum level of survival probability compared to the reference curve. THis ensures that:

* PFS < TTP

:::

```{r}
p$surv$st <- lapply(p$surv$st, function(popu) {
  popu$line_5 <- popu$line_4
  return(popu)
})
```


::: {.callout-note collapse="true"}

Sets survival times for 5L (best supportive care) to 4L, when its come after four active treatments

:::

::: {.callout-warning collapse="true"}

Uncommented these. It allows us to look at an example - here, population 0 line 1 molecule 1 trial 2. It shows us the extrapolated survival curves and transition probabilities.

:::

```{r}
f_qc_surv_ExtrapPlot(
  st   = p$surv$st,
  popu = "pop_0",
  li   = "line_1",
  mo   = "mol_1",
  tr   = "trial_2",
  t_yr = p$basic$t_yr,
  th = p$basic$th
)

f_qc_surv_EstHazPlot(
  st   = p$surv$st,
  gpop = p$surv$gpop,
  popu = "pop_0",
  li   = "line_1",
  mo   = "mol_1",
  tr   = "trial_2",
  t_yr = p$basic$t_yr,
  th   = p$basic$th
)
```

```{r}
if (qc_mode) {
  i$excel_destinations <- data.table(i$R_table_eff_data_settings)[Include.in.this.analysis.=="Yes",list(Population,Treatment.line,Molecule,Origin.trial,End.point)]
  i$surv$ExtrapSenseCheck <- Reduce(
    x = 1:nrow(i$excel_destinations),
    init = f_NMA_generateNetwork(i$id$ipd,i$lookup$ipd),
    accumulate = FALSE,
    f = function(prev, dest_row) {
      dat <- as.list(i$excel_destinations[dest_row,])
      
      d <- list(
        pop = paste0("pop_",dat$Population),
        line = paste0("line_",dat$Treatment.line),
        mol = paste0("mol_",dat$Molecule),
        trial = paste0("trial_",dat$Origin.trial),
        endpoint = paste0("endpoint_",dat$End.point)
      )
      
      cat(paste0(
        "Drawing plots: ",
        " row ", dest_row, " i$surv$ExtrapSenseCheck$",
        d$pop, "$",
        d$line, "$",
        d$mol, "$",
        d$trial, "$plots",
        "\n"
      ))
      
      p_extrap <- f_qc_surv_ExtrapPlot(
        st   = p$surv$st,
        popu = d$pop,
        li   = d$line,
        mo   = d$mol,
        tr   = d$trial,
        t_yr = p$basic$t_yr,
        th = p$basic$th
      )
      
      p_haz <- f_qc_surv_EstHazPlot(
        st   = p$surv$st,
        gpop = p$surv$gpop,
        popu = d$pop,
        li   = d$line,
        mo   = d$mol,
        tr   = d$trial,
        t_yr = p$basic$t_yr,
        th   = p$basic$th
      )
      
      plmt <- prev[[d$pop]][[d$line]][[d$mol]][[d$trial]]
      plmt$plots <- list(
        p_extrap = p_extrap,
        p_haz = p_haz
      )
      
      # Save 2 plots for each PLM available. Takes a while to run.
      if (qc_mode) {
        ggsave(
          filename = file.path("./4_Output",paste0("p_extrap_",paste(d[1:4],collapse="_"),".png")),
          plot     = plmt$plots$p_extrap,
          device = "png",
          units = "cm",
          width = 15
        )
        ggsave(
          filename = file.path("./4_Output",paste0("p_tp_",paste(d[1:4],collapse="_"),".png")),
          plot     = plmt$plots$p_haz,
          device = "png",
          units = "cm",
          width = 15
        )
      }
      
      prev[[d$pop]][[d$line]][[d$mol]][[d$trial]] <- plmt
      
      return(prev)
      
    }
  )
}
```

::: {.callout-note collapse="true"}

This takes a while to run, but is not currently as qc_mode is FALSE. If we were to run it, it would plot survival extrapolations and hazard curves for each PLMTE (like done for the example above).

:::

## Processing data

This section processes data on demographics, QALYs, costs, AEs, costs, subsequent treatments, and population mappings.

```{r}
p$surv$prop_deathinPFS <- i$dd_prop_deathinPFS

p$demo$agg <- f_cleaning_ptchar(i$R_table_ptchar, i$lookup)

p$demo$live <- p$demo$agg

p <- add_population_utility_params(p, psa = FALSE, .i = i)
```

::: {.callout-note collapse="true"}

Adds a few different parameters to p.

:::

```{r}
base_utility <- data.frame(cycle = 0:p$basic$th, utility = 1)
if (i$dd_ageadjuutilities == "Yes") {
  if (i$dd_age_sex_source == "Mean") {
    ptc_L1 <- i$R_table_ptchar[Treatment.line == 1, c(1, 3, 4)]
    colnames(ptc_L1) <- c("Population", "age", "sex")
    ptc_L1$sex <- 1 - ptc_L1$sex
    ptc_L1 <- merge(ptc_L1, i$lookup$ipd$pop, by.x = "Population", by.y = "Description")
    ptc_L1 <- ptc_L1[order(ptc_L1$Number), c("age", "sex", "Number")]
    ptc_L1 <- split(ptc_L1[, c("age", "sex")], paste0("pop_", ptc_L1$Number))
    
    p$util$gpop <- lapply(ptc_L1, function(pop) adjust_utility(
      age            = pop$age,
      sex            = pop$sex,
      utilities      = base_utility,
      .patient_level = FALSE,
      .p             = p
    ))
    
  } else {
    ipd_L1 <- i$R_table_patientagesex$Line == 1
    p$util$gpop <- list()
    p$util$gpop$pop_0 <- adjust_utility(
      age            = i$R_table_patientagesex$Age[ipd_L1],
      sex            = if_else(i$R_table_patientagesex$Gender[ipd_L1] == "M", "male", "female"),
      utilities      = base_utility,
      .patient_level = TRUE,
      .p             = p
    )
    p$util$gpop$pop_1 <- p$util$gpop$pop_0
    p$util$gpop$pop_2 <- p$util$gpop$pop_0
  }
} else {
  p$util$gpop <- list(pop_0 = 1, pop_1 = 1, pop_2 = 1)
}                 
```

::: {.callout-note collapse="true"}

We start with `base_utility`, which is a table with 2089 rows (which is the time horizon `TH`), where each row is a cycle. For each, the utility is set to 1. This basically means that every individual in the population starts with a full quality of life (utility value of 1).

```{r}
unique(base_utility$utility)
```

However, if `i$dd_ageadjuutilities=="Yes"`, then it is adjusted based on the age and sex of either:

* The population (if based on means) (`i$dd_age_sex_source == "Mean"`)
* The individual patients (if based on individual patients)

```{r}
i$dd_ageadjuutilities
i$dd_age_sex_source
```

The result is utilities for each population (pop_0, pop_1, pop_2) for each cycle - for example:

```{r}
head(p$util$gpop$pop_0, 5)
```

:::

```{r}
rm(base_utility)

i$QALYs <- list()

i$QALYs$utilities$means <- f_process_utilities(raw_utilities = i$R_table_util,
                                               PSA = FALSE,
                                               samples = FALSE)
```

::: {.callout-note collapse="true"}

The raw table of utilities is as follows:

```{r}
head(i$R_table_util, 2)
```

The function `f_process_utilities()` extracts and renames some of these columns.

```{r}
head(i$QALYs$utilities$means, 2)
```

However, if `PSA = TRUE`, it would generate multiple samples of utility values for use in probabilistic sensitivity analysis.

:::

```{r}
p$util$mk <- data.table(i$QALYs$utilities$means)

p$ae$aetype <- i$dd_apply_AE_options

p$ae$duration <- data.table(i$R_table_AE_rates)

p$ae$mk$per_cycle <- data.table(f_process_adverse_events(
  AE_costs = i$R_table_AE_costs,
  AE_disutil = i$R_table_AE_util,
  AE_duration = i$R_table_duration,
  AE_rate = i$R_table_AE_rates,
  comparators = i$lookup$trt,
  weeks_per_year = p$basic$cl_w / p$basic$cl_y,
  PSA = FALSE
))

p$ae$mk$per_cycle[trt == "BSC",]$trt <- i$lookup$ipd$mol[match(999,Number),]$RCC_input_desc

p$ae$mk$per_cycle$molecule <- i$lookup$ipd$mol[match(p$ae$mk$per_cycle$trt,RCC_input_desc),]$Number

p$ae$approach <- i$dd_apply_AE_options
```

::: {.callout-note collapse="true"}

Some processing and adding of parameters to `p`.

:::

```{r}
i$cost <- list()

p$costs$mk <- f_process_cost_data(
  drug_and_admin  = i$R_table_drug_admin_costs,
  per_cycle_costs = i$R_table_MRU,
  time_horizon    = p$basic$th,
  max_trt_lines   = p$basic$R_maxlines,
  RDI_source      = i$dd_sc_RDI,
  verbose         = FALSE,
  PSA             = FALSE, 
  samples         = 1)
```

::: {.callout-note collapse="true"}

This function makes a nested list with:

* Drug costs (`drug`)
* Costs of drug administration (`admin`)
* Medical resource use (MRU) costs (`mru_on` and `mru_off`)

These costs are per cycle for each molecule and line.

```{r}
length(p$costs$mk$drug$line_1$mol_4)

# Example
head(p$costs$mk$drug$line_1$mol_4, 8)
```

:::

```{r}
p$costs$oneoff <-  f_process_other_cost_data(
  one_off_costs = i$R_table_MRU_oneoff,
  PSA = FALSE
)

p$costs$oneoff_mk <- p$costs$oneoff[,.(cost = sum(cost)),by=list(Apply.to)]
p$costs$oneoff_mk <- lapply(structure(
  p$costs$oneoff_mk$Apply.to,
  .Names = p$costs$oneoff_mk$Apply.to
), function(x) {
  p$costs$oneoff_mk[Apply.to == x, ]$cost
})
```

::: {.callout-note collapse="true"}

Produces table with some one-off costs - end of life/terminal care, subsequent radiotherapy, and subsequent surgery.

```{r}
p$costs$oneoff
```

:::

```{r}
if (FALSE) {
  i$cost$drug_and_admin_cost_by_tunnel_state$PSA <- f_process_drug_and_admin_cost_data(
    raw_table = i$R_table_drug_admin_costs,
    PSA_samples = TRUE)
}  
```

::: {.callout-note collapse="true"}

This code is never run in this file, but is for the probabilistic sensitivity analysis.

:::

```{r}
p$substrt$partsa  <- as.data.table(f_process_subs_txt_data(
  subs_txt = i$R_table_sub_txt_cum_costs,
  PSA             = FALSE
))
```

::: {.callout-note collapse="true"}

For each treatment and population, table has drug cost, admin cost, and the cost and QALY impact of adverse events.

```{r}
head(p$substrt$partsa, 5)
```

:::

```{r}
p$basic$lookup$pop_map <- data.table(i$r_overall_lookup_pop)
```

::: {.callout-note collapse="true"}

As in the `Model_Structure.py` comments, there are:

* Three risk populations (all risk, favourable risk, int/poor risk)
* Two IO populations - whether or not patients had prior adjuvant therapy with immune-oncology treatment

These leads to six possible combinations overall. We can use this table to map from those six, to those used in the analysis:

* Treatment sequences are sorted into 4 populations (`Sequencing.population.number`)
* Survival extrapolations, costs, QALYs and AEs are sorted into 3 populations (`Risk.population.number`)

```{r}
p$basic$lookup$pop_map
```

:::

## Economic modelling

::: {.callout-warning collapse="true"}

Changed paths

:::

```{r}
i$R_table_eff_data_settings <- data.table(i$R_table_eff_data_settings)
p$releff$excel_table <- i$R_table_eff_data_settings

if(!str_trim(i$dd_model_struct) %in% c("State transition", "Partitioned survival")) stop(
  "The model structure is not one of the available options. These are 'State transition' and 'Partitioned survival'. Either code or the excel file are out of date or wrongly set up"
)

pf <- list()
res <- list()

stopifnot(p$basic$structure %in% c("State transition","Partitioned survival"))

if(p$basic$decision_problem == "cabo+nivo") {
  p$basic$pops_to_run <- 1:3
} else {
  p$basic$pops_to_run <- NULL
}

saveRDS(p,"../2_Scripts/standalone scripts/QC/p.rds")
saveRDS(i,"../2_Scripts/standalone scripts/QC/i.rds")
```

::: {.callout-note collapse="true"}

Adds the settings from excel to `p`.

```{r}
head(p$releff$excel_table, 5)
```

And checks model structure is correct.

```{r}
i$dd_model_struct
```

Then some settings specifically if decision problem is cabo+nivo only

```{r}
p$basic$decision_problem
p$basic$pops_to_run
```

Then it saves `p` and `i` to R data files, for quality control purposes, so you can easily reload those and repeat results.

:::

### Run the model

::: {.callout-warning collapse="true"}

Add option to not run this section.

:::

```{r, computepf}
run_computepf = FALSE

if(run_computepf) {
  tick <- Sys.time()
  pf <- f_pf_computePF(
    p           = p,
    struct      = p$basic$structure,
    verbose     = FALSE,
    plots       = FALSE,
    just_pop    = p$basic$pops_to_run,
    just_nlines = NULL,
    just_seq    = NULL
  )
  print(Sys.time() - tick)
}

save_computepf = FALSE
computepf_file = file.path(path_data, "computepf_example.rds")

if(save_computepf) {
  saveRDS(pf, file=computepf_file)
}

load_computepf = TRUE

if(load_computepf) {
  pf <- readRDS(computepf_file)
}
```

::: {.callout-note collapse="true"}

We find the patient flow using `f_pf_compute_PF()`. This function will use either:

* `f_pf_computePF_mk()` (if state transition model, i.e. Markov model)
* `f_pf_computePF_ps()` (if partitioned survival model)

The purpose of this is to model how patients move through different health states/treatments, from which we can find outputs like costs and utilities.

**State transition model**. Steps include:

* Getting relevant population data and creating `sequence_list` with the allowed treatment sequences for a given population
* Creating `util_gpop_mat` - a matrix of health state utility values that account for ageing
* Transition probabilities (`TPs`) are calculated for each sequence, then used to construct Markov traces (`TRACE`) (ie. matrix of state vectors across all model cycles)
* These are used to calculate costs through the treatment sequence (`pf_costs`) (e.g. cost per cycle `cpc`, costs on initiation `coi`, and costs on death `cod`), QALYs `pf_qalys`) and adverse events (`pf_ae`)

**Partitioned survival model**. Steps include:

* Getting relevant population data and creating the utility matrix `util_gpop_mat`
* Using `f_pf_partSA_state_res()`, simulates patient states (e.g. PFS) across time horizon for each treatment sequence, returns the costs (`costs`) and qalys (`qalys`)

:::

### Compile model results

```{r}
Scenario_number <- i$R_Scenario_num

if(Scenario_number == 0) {detail_level <- 5} else {detail_level <- 4}

res <- f_res_compute_results(
  pf              = pf,
  structure       = p$basic$structure,
  p               = p,
  detail_level    = detail_level,
  vs_mol          = 1,
  no_active_lines = i$R_max_trt_lines
)
```

::: {.callout-note collapse="true"}

`f_res_compute_results()` processes the results using:

* `f_res_compute_results_mk()` for the state transition model
* `f_res_compute_results_ps()` for the partitioned survival model

These each in turn utilities various other functions to summarise the model results. There are various functions, depending on the level of detail desired in the plots. This is set to either 4 or 5, depending on whether it is scenario 0.

The summary functions include:

* `f_pf_mk_summary()` to get `undisc` and `disc` results (undiscounted and discounted)
* `f_res_mk_incremental()` to get `incremental`
* `f_res_wa_model()` to get `weighted_model` discounted or undiscounted, summarised using `f_res_sum_weighted_model()`
* `f_pf_wa_sr_plots()` to get `weighted_trace_plots`

And more! As summarised in `Model_Structure.py`, the outcomes of this from each detail level are:

1. Top line results by sequence and weighted average results (costs, QALYs, LYs)
2. Include incremental analysis (from `f_res_mk_incremental()`)
3. Include weighted average pairwise comparisons
4. Include incremental analysis by sequence
5. Include trace plots

Except for the partitioned survival, 4 is breakdown tables and 4 is state residency plots.

Some examples...

```{r}
head(res$undisc$pop_1$ly$breakdown, 3)
head(res$incremental$pop_1$expanded_results, 3)
res$weighted_trace_plots$pop_1$plots$L1_1
res$wa_summarised$pop_1$costs
res$pairwise_vs_mol$pop_1$qalys
```

:::

```{r}
if (p$basic$structure == "State transition") {
  population_numbers <- if(sum(p$basic$pops_to_run == 1:3)>0){1:3} else{1:6}
  res$mk$qaly_shortfall_1_to_3 <- lapply(population_numbers, function(npa_pop) {
  
  lu_pop <- p$basic$lookup$pop_map
  lu_rpop <- p$basic$lookup$ipd$pop
  
  # npa_pop is overall population, we need to look up risk population from it:
  
  risk_pop_n <- lu_pop[match(npa_pop,lu_pop$Overall.population.number),]$Risk.population.number
  risk_pop <- lu_rpop[match(risk_pop_n,lu_rpop$Number),]$Description  
  
  i$R_table_ptchar <- as.data.table(i$R_table_ptchar)
  
  if (i$dd_age_sex_source == "Mean") {
    
    # So for this risk population, we need the baseline characteristics:
    bl_chars <- i$R_table_ptchar[Population == risk_pop & Treatment.line == 1,]
    bl_age  <- bl_chars$Starting.age..years..Mean
    bl_male <- 1-bl_chars$Starting...female.Mean
    
  } else {
    
    patient_sex_age_IPD <- as.data.table(i$R_table_patientagesex)
    patient_sex_age_IPD$Gender <- replace(patient_sex_age_IPD$Gender, patient_sex_age_IPD$Gender=="M","male")
    patient_sex_age_IPD$Gender <- replace(patient_sex_age_IPD$Gender, patient_sex_age_IPD$Gender=="F","female")
    
    bl_age <- patient_sex_age_IPD[Line ==1]$Age 
    bl_male <- patient_sex_age_IPD[Line ==1]$Gender
    
  }
  
  pna_txt <- names(res$wa_summarised)[npa_pop]
  
  tab <- res$wa_summarised[[pna_txt]][L1 != 1,]
  
  met <- tab[which.max(qalys),]
  
  q_met <- met$qalys
  comp_no_met <- met$L1
  
  out <-    calc_severity_modifier(
    age = bl_age,
    sex = bl_male,
    .patient_level = if(i$dd_age_sex_source == "Mean") {FALSE} else {TRUE},  
    qalys = q_met,
    .i = i,
    .p = p
  )
  
  out <- cbind(out, SOC = comp_no_met)
  
  return(out)
  
})
}

Scenario_name <- i$R_Scenario_name    # Use ST for state transition, PS for Partitioned survival, LP for list price, cPAS for cPAS
Scenario_number <- i$R_Scenario_num
Run_date <- date()
```

::: {.callout-note collapse="true"}

Applies a severity modifier for the weighted average 1L treatment comparison. This calculation is only provided for the state transition model. There is processing for this, then the modifier is calculated using `calc_severity_modifier()`, which in turn uses `get_severity_modifier()` to find the appropriate severity modifier according to the discounted QALYs for those with the condition and those without.

```{r}
population_numbers

res$mk$qaly_shortfall_1_to_3
```

:::

::: {.callout-warning collapse="true"}

Changed paths

:::

```{r}
if (p$basic$structure == "State transition") {
  saveRDS(res, paste0("../4_Output/ST_Scenario ",Scenario_number,"_",i$dd_drug_price_options,gsub(":","_",Run_date),".rds"))
} else {
  saveRDS(res, paste0("../4_Output/PartSA_Scenario ",Scenario_number,"_",i$dd_drug_price_options,gsub(":","_",Run_date),".rds"))
}
```

::: {.callout-warning collapse="true"}

Changed function to have `folder` input so it allows me to alter the output path

:::

```{r}
Word_width_inches      <-  29.7*0.3937

f_res_ProduceWordDoc(
  p                      = p,
  res                    = res,
  Scenario_name          = i$R_Scenario_name,
  Scenario_number        = i$R_Scenario_num,
  price_options          = i$dd_drug_price_options,
  Run_date               = Run_date,
  word_template_location = "../3_Functions/reporting/empty results doc.docx",
  Word_width_inches      = 29.7*0.3937,
  auto_save              = TRUE,
  verbose = TRUE,
  folder = path_output
)
```

::: {.callout-warning collapse="true"}

Depending on `p$basic$structure`, will either use `f_res_ProduceWordDoc_ST` (st - state transition) or `f_res_ProduceWordDoc_PS` (ps - partitioned survival) to produce the report content.

In the default case, this is state transition.

```{r}
p$basic$structure
```

This applies results tables specific to the cabo+nivo population to the word document, in the format required by NICE.

:::